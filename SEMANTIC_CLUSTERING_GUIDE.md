# SeekMoney AI - è¯­ä¹‰èšç±»ç³»ç»ŸæŠ€æœ¯æ–‡æ¡£

## ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
3. [æ•°æ®æ¸…æ´—æ¨¡å—](#æ•°æ®æ¸…æ´—æ¨¡å—)
4. [Embedding æ¨¡å—](#embedding-æ¨¡å—)
5. [èšç±»ç®—æ³•æ¨¡å—](#èšç±»ç®—æ³•æ¨¡å—)
6. [å‚æ•°ä¼˜åŒ–ç­–ç•¥](#å‚æ•°ä¼˜åŒ–ç­–ç•¥)
7. [è´¨é‡è¯„ä¼°æŒ‡æ ‡](#è´¨é‡è¯„ä¼°æŒ‡æ ‡)
8. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
9. [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
10. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## ç³»ç»Ÿæ¦‚è¿°

### è®¾è®¡ç†å¿µ

SeekMoney AI çš„è¯­ä¹‰èšç±»ç³»ç»Ÿé‡‡ç”¨ **æ™ºè°±AI Embedding + DBSCAN** çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œæ›¿ä»£äº†åŸæœ‰çš„ Jaccard ç›¸ä¼¼åº¦èšç±»ç®—æ³•ã€‚è¯¥è®¾è®¡æ—¨åœ¨ä»ç¤¾äº¤åª’ä½“ç”¨æˆ·è¯„è®ºä¸­è‡ªåŠ¨è¯†åˆ«å’Œæå–æœ‰æ„ä¹‰çš„ç”¨æˆ·ç—›ç‚¹èšç±»ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **è¯­ä¹‰ç†è§£** | åŸºäº Embedding å‘é‡ï¼Œç†è§£æ–‡æœ¬è¯­ä¹‰è€Œéå­—é¢åŒ¹é… |
| **æ— ç›‘ç£å­¦ä¹ ** | DBSCAN æ— éœ€é¢„å…ˆæŒ‡å®šèšç±»æ•°é‡ï¼Œè‡ªåŠ¨å‘ç°æ•°æ®ç»“æ„ |
| **å™ªéŸ³è¿‡æ»¤** | å†…ç½®é«˜ä¿¡å™ªæ¯”æ•°æ®æ¸…æ´—å™¨ï¼Œè¿‡æ»¤æ— æ•ˆç¤¾äº¤ç”¨è¯­ |
| **è‡ªé€‚åº”å‚æ•°** | æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´èšç±»å‚æ•° |
| **è´¨é‡è¯„ä¼°** | ä½¿ç”¨ Silhouette Score å’Œ Davies-Bouldin Index è¯„ä¼°èšç±»è´¨é‡ |

### æŠ€æœ¯æ ˆ

```python
æ ¸å¿ƒä¾èµ–:
- numpy: å‘é‡è¿ç®—
- sklearn: DBSCAN èšç±»ç®—æ³•ã€è·ç¦»è®¡ç®—ã€è´¨é‡è¯„ä¼°
- æ™ºè°±AI Embedding API: æ–‡æœ¬å‘é‡åŒ–
```

---

## æ ¸å¿ƒæ¶æ„

### ç³»ç»Ÿæµç¨‹å›¾

```
åŸå§‹æ–‡æœ¬è¾“å…¥
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®æ¸…æ´—æ¨¡å— (DataCleaner)          â”‚
â”‚  - è¿‡æ»¤å™ªéŸ³æ–‡æœ¬                      â”‚
â”‚  - å»é‡                              â”‚
â”‚  - è®¡ç®—è´¨é‡åˆ†æ•°                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ æ¸…æ´—åæ–‡æœ¬åˆ—è¡¨ + è´¨é‡åˆ†æ•°
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding æ¨¡å— (ZhipuEmbedding)     â”‚
â”‚  - è°ƒç”¨æ™ºè°±AI API                   â”‚
â”‚  - æ‰¹é‡å¤„ç† + é™æµæ§åˆ¶               â”‚
â”‚  - è¿”å›å‘é‡çŸ©é˜µ (N Ã— 1024)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ Embedding å‘é‡çŸ©é˜µ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‚æ•°ä¼˜åŒ–æ¨¡å— (å¯é€‰)                 â”‚
â”‚  - ç½‘æ ¼æœç´¢æœ€ä¼˜å‚æ•°                  â”‚
â”‚  - æœ€å¤§åŒ– Silhouette Score           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ æœ€ä¼˜ (eps, min_samples)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  èšç±»æ¨¡å— (SemanticClusterer)        â”‚
â”‚  - DBSCAN èšç±»                      â”‚
â”‚  - è®¡ç®—ä½™å¼¦è·ç¦»çŸ©é˜µ                  â”‚
â”‚  - æå–ä»£è¡¨æ€§æ–‡æœ¬                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ èšç±»ç»“æœ
è¾“å‡º: [
  {
    "representative_text": "ä»£è¡¨æ€§æ–‡æœ¬",
    "size": èšç±»å¤§å°,
    "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", ...]
  },
  ...
]
```

---

## æ•°æ®æ¸…æ´—æ¨¡å—

### DataCleaner ç±»

æ•°æ®æ¸…æ´—æ˜¯æ•´ä¸ªæµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œä¹Ÿæ˜¯æœ€å…³é”®çš„ä¸€æ­¥ã€‚é«˜è´¨é‡çš„è¾“å…¥æ•°æ®ç›´æ¥å†³å®šèšç±»æ•ˆæœã€‚

```python
class DataCleaner:
    def __init__(self, min_length: int = 4)
    def is_noise(self, text: str) -> bool
    def has_whitelist_keyword(self, text: str) -> bool
    def calculate_score(self, text: str) -> float
    def clean(self, texts: List[str]) -> Tuple[List[str], List[float]]
```

### å™ªéŸ³è¿‡æ»¤è§„åˆ™

#### 1. æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ (NOISE_PATTERNS)

```python
# ç¤ºä¾‹å™ªéŸ³æ¨¡å¼
r'^å“ˆ+$'           # çº¯å“ˆå“ˆå“ˆ â†’ è¿‡æ»¤
r'^@\S+'           # @æŸäºº â†’ è¿‡æ»¤
r'^[\d\.]+$'       # çº¯æ•°å­— â†’ è¿‡æ»¤
r'^ğŸ‘â¤ï¸ğŸ’•\s*]+$'    # çº¯è¡¨æƒ… â†’ è¿‡æ»¤
```

#### 2. å™ªéŸ³çŸ­è¯­åˆ—è¡¨ (NOISE_PHRASES)

åŒ…å« 8 å¤§ç±»æ— æ•ˆç¤¾äº¤ç”¨è¯­ï¼š

| ç±»åˆ« | ç¤ºä¾‹ | æ•°é‡ |
|------|------|------|
| çº¯èµç¾ | å¥½å¬ã€å¥½çœ‹ã€666ã€ç‰›æ‰¹ | 14ä¸ª |
| çº¯æƒ…ç»ª | å“ˆå“ˆå“ˆã€ç¬‘æ­»ã€çˆ±äº† | 8ä¸ª |
| è¿½æ›´ç±» | è¹²ã€è¹²ä¸€ä¸ªã€å‚¬æ›´ | 5ä¸ª |
| å ä½ç±» | ç¬¬ä¸€ã€æ²™å‘ã€æ‰“å¡ | 7ä¸ª |
| å£å·ç±» | æ”¯æŒã€åŠ æ²¹ã€yyds | 6ä¸ª |
| ç®€å•ç–‘é—® | å•¥ã€å•¥æ„æ€ã€çœŸçš„å— | 11ä¸ª |
| èº«ä»½è¯¢é—® | æ˜¯è°ã€è°å•Šã€åšä¸»æ˜¯è° | 5ä¸ª |
| å¹¿å‘Šè¥é”€ | ç§ä¿¡ã€åŠ Vã€æ‰«ç  | 7ä¸ª |

#### 3. ç™½åå•å…³é”®è¯ (WHITELIST_KEYWORDS)

åŒ…å« 63 ä¸ªä¸ç”¨æˆ·ç—›ç‚¹ç›¸å…³çš„ä¼˜å…ˆä¿ç•™è¯æ±‡ï¼š

```python
# åˆ†ç±»ç»Ÿè®¡
é—®é¢˜è¡¨è¾¾:  æ€ä¹ˆã€å¦‚ä½•ã€ä¸ºä»€ä¹ˆã€éš¾ã€å‘ã€éº»çƒ¦ (9ä¸ª)
éœ€æ±‚è¡¨è¾¾:  æ±‚ã€å¸Œæœ›ã€å»ºè®®ã€æ¨èã€æƒ³è¦ (7ä¸ª)
å­¦ä¹ å›°éš¾:  ä¸æ‡‚ã€ä¸ä¼šã€å­¦ä¸ä¼šã€å¤ªéš¾ (6ä¸ª)
ä½“éªŒé—®é¢˜:  åæ‚”ã€é¿é›·ã€è¸©å‘ã€ä¸å¥½ç”¨ (7ä¸ª)
ä»·æ ¼æ•æ„Ÿ:  è´µã€ä¾¿å®œã€å¹³æ›¿ã€çœé’± (7ä¸ª)
è´¨é‡æŠ•è¯‰:  åæ§½ã€å·®è¯„ã€é€€æ¬¾ã€å”®å (6ä¸ª)
æŠ€æœ¯é—®é¢˜:  bugã€å¡ã€é—ªé€€ã€å´©æºƒ (7ä¸ª)
å¯¹æ¯”é€‰æ‹©:  å“ªä¸ªã€å“ªé‡Œã€åŒºåˆ« (6ä¸ª)
æ•™ç¨‹æŒ‡å¯¼:  æ•™ç¨‹ã€æ­¥éª¤ã€æ–¹æ³• (6ä¸ª)
```

### æ–‡æœ¬è´¨é‡è¯„åˆ†ç®—æ³•

```python
def calculate_score(self, text: str) -> float:
    """
    è´¨é‡åˆ†æ•°è®¡ç®—å…¬å¼:

    åŸºç¡€åˆ†: 1.0

    ç™½åå•å…³é”®è¯:    +2.0
    é•¿åº¦ 50-200:     +1.0 (æœ€ä½³é•¿åº¦)
    é•¿åº¦ 20-50:      +0.5
    é•¿åº¦ 10-20:      +0.2
    é•¿åº¦ > 300:      -0.5 (è¿‡é•¿å¯èƒ½å¤åˆ¶)

    åŒ…å«é—®å·:        +0.3 Ã— min(é—®å·æ•°, 2)
    åŒ…å«æ•°å­—:        +0.3
    æ„Ÿå¹å· > 2:      -0.5 (æƒ…ç»ªåŒ–)

    ç®€å•ç–‘é—®+çŸ­æ–‡æœ¬: -1.0 (æ— å®è´¨å†…å®¹)
    """
```

**è¯„åˆ†ç¤ºä¾‹ï¼š**

| æ–‡æœ¬ | åˆ†æ•° | è¯´æ˜ |
|------|------|------|
| "è¿™ä¸ªäº§å“çœŸçš„å¾ˆéš¾ç”¨ï¼Œå®¢æœä¹Ÿä¸ç†äºº" | 3.3 | ç™½åå•å…³é”®è¯(éš¾)+é•¿åº¦é€‚ä¸­+åŒ…å«é—®å· |
| "å¥½å¥½å¥½å¥½å¥½å¥½å¥½" | 1.0 | åŸºç¡€åˆ†ï¼Œè¢«è¿‡æ»¤ä¸ºå™ªéŸ³ |
| "æ±‚æ¨èä¸€æ¬¾æ€§ä»·æ¯”é«˜çš„å­¦ä¹ è½¯ä»¶" | 3.3 | ç™½åå•å…³é”®è¯(æ±‚ã€æ€§ä»·æ¯”)+é•¿åº¦é€‚ä¸­ |
| "èµ" | 1.0 | åŸºç¡€åˆ†ï¼Œè¢«è¿‡æ»¤ä¸ºå™ªéŸ³ |
| "è¿™ä¸ªæ€ä¹ˆç”¨ï¼Ÿä¸å¤ªæ‡‚ï¼Œæœ‰æ²¡æœ‰æ•™ç¨‹ï¼Ÿ" | 3.2 | ç™½åå•å…³é”®è¯(æ€ä¹ˆã€ä¸æ‡‚ã€æ•™ç¨‹)+é—®å· |

---

## Embedding æ¨¡å—

### ZhipuEmbedding ç±»

ä½¿ç”¨æ™ºè°±AIçš„ Embedding-3 æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ã€‚

```python
class ZhipuEmbedding:
    def __init__(self, api_key: Optional[str] = None)
    def get_embeddings(self, texts: List[str]) -> np.ndarray
```

### API é…ç½®

```python
base_url = "https://open.bigmodel.cn/api/paas/v4/embeddings"
model = "embedding-3"  # å¯é€šè¿‡ GLM_EMBEDDING_MODEL ç¯å¢ƒå˜é‡é…ç½®
batch_size = 25       # æ¯æ‰¹æœ€å¤§æ•°é‡
rate_limit_delay = 0.5  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env.local æˆ– .env
GLM_API_KEY=your_api_key_here
GLM_EMBEDDING_MODEL=embedding-3  # å¯é€‰ï¼Œé»˜è®¤ä¸º embedding-3
```

### æ‰¹é‡å¤„ç†ç­–ç•¥

```python
def get_embeddings(self, texts: List[str]) -> np.ndarray:
    """
    æ‰¹é‡å¤„ç†é€»è¾‘:

    1. å°†è¾“å…¥æ–‡æœ¬åˆ†æ‰¹ (æ¯æ‰¹æœ€å¤š25æ¡)
    2. é€ä¸ªè°ƒç”¨ API (æ™ºè°± API ä¸æ”¯æŒæ‰¹é‡)
    3. æ·»åŠ å»¶è¿Ÿé¿å…é™æµ (0.5ç§’/è¯·æ±‚)
    4. è¿”å› numpy æ•°ç»„ (N Ã— 1024)
    """
```

**æ—¶é—´ä¼°ç®—ï¼š**

- 100 æ¡æ–‡æœ¬: ~12.5 ç§’
- 200 æ¡æ–‡æœ¬: ~25 ç§’
- 500 æ¡æ–‡æœ¬: ~62.5 ç§’

---

## èšç±»ç®—æ³•æ¨¡å—

### DBSCAN ç®—æ³•ç®€ä»‹

DBSCAN (Density-Based Spatial Clustering of Applications with Noise) æ˜¯ä¸€ç§åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•ã€‚

**æ ¸å¿ƒæ¦‚å¿µï¼š**

```
eps (Îµ):        é‚»åŸŸåŠå¾„ï¼Œå®šä¹‰ç‚¹ä¹‹é—´çš„è·ç¦»é˜ˆå€¼
min_samples:    å½¢æˆèšç±»çš„æœ€å°ç‚¹æ•°
æ ¸å¿ƒç‚¹:         é‚»åŸŸå†…è‡³å°‘æœ‰ min_samples ä¸ªç‚¹çš„ç‚¹
è¾¹ç•Œç‚¹:         é‚»åŸŸå†…ç‚¹æ•°ä¸è¶³ min_samplesï¼Œä½†åœ¨æŸä¸ªæ ¸å¿ƒç‚¹çš„é‚»åŸŸå†…
å™ªéŸ³ç‚¹:         æ—¢ä¸æ˜¯æ ¸å¿ƒç‚¹ä¹Ÿä¸æ˜¯è¾¹ç•Œç‚¹çš„ç‚¹
```

### ä½™å¼¦è·ç¦»

ä½¿ç”¨ä½™å¼¦è·ç¦»è€Œéæ¬§æ°è·ç¦»ï¼Œæ›´é€‚åˆé«˜ç»´æ–‡æœ¬å‘é‡ï¼š

```python
cosine_distance(a, b) = 1 - cosine_similarity(a, b)

# èŒƒå›´: [0, 2]
# 0 = å®Œå…¨ç›¸åŒ
# 1 = æ­£äº¤ (æ— ç›¸ä¼¼æ€§)
# 2 = å®Œå…¨ç›¸å
```

### SemanticClusterer ç±»

```python
class SemanticClusterer:
    def __init__(self, eps: float = 0.25, min_samples: int = 3)
    def cluster(self, embeddings, texts, scores) -> List[Dict]
```

### èšç±»è¾“å‡ºæ ¼å¼

```python
[
    {
        "representative_text": "è·ç¦»èšç±»ä¸­å¿ƒæœ€è¿‘çš„æ–‡æœ¬",
        "size": 15,                    # èšç±»å¤§å°ï¼ˆå»é‡åï¼‰
        "texts": [                     # èšç±»ä¸­çš„æ‰€æœ‰æ–‡æœ¬
            "æ–‡æœ¬1",
            "æ–‡æœ¬2",
            ...
        ]
    },
    ...
]
```

### ä»£è¡¨æ€§æ–‡æœ¬é€‰æ‹©ç®—æ³•

```python
# ç»¼åˆè€ƒè™‘è·ç¦»å’Œè´¨é‡åˆ†æ•°
combined_score = -distance + score * 0.3

# distance: è·ç¦»èšç±»ä¸­å¿ƒçš„ä½™å¼¦è·ç¦» (è¶Šå°è¶Šå¥½)
# score: æ–‡æœ¬è´¨é‡åˆ†æ•° (è¶Šé«˜è¶Šå¥½)
# æƒé‡ 0.3: è´¨é‡åˆ†æ•°çš„æƒé‡
```

---

## å‚æ•°ä¼˜åŒ–ç­–ç•¥

### è‡ªåŠ¨å‚æ•°ä¼˜åŒ–

```python
def optimize_clustering_params(
    embeddings: np.ndarray,
    eps_range: List[float] = [0.2, 0.25, 0.3],
    min_samples_range: Optional[List[int]] = None
) -> Tuple[float, int]
```

### ä¼˜åŒ–ç›®æ ‡

**æœ€å¤§åŒ– Silhouette Score:**

```
Silhouette Score = (b - a) / max(a, b)

å…¶ä¸­:
a = æ ·æœ¬åˆ°åŒç°‡å…¶ä»–æ ·æœ¬çš„å¹³å‡è·ç¦» (å†…èšåº¦)
b = æ ·æœ¬åˆ°æœ€è¿‘å¼‚ç°‡æ ·æœ¬çš„å¹³å‡è·ç¦» (åˆ†ç¦»åº¦)

èŒƒå›´: [-1, 1]
-1:  èšç±»æ•ˆæœæå·®
0:   èšç±»é‡å 
1:   èšç±»æ•ˆæœå®Œç¾
```

### eps å‚æ•°é€‰æ‹©

| æ•°æ®è§„æ¨¡ | æ¨è eps | è¯´æ˜ |
|----------|---------|------|
| < 20 | 0.45 | æå®½æ¾ï¼Œç¡®ä¿èƒ½å½¢æˆèšç±» |
| 20-50 | 0.38 | è¾ƒå®½æ¾ï¼Œé¿å…è¿‡åº¦åˆ†æ•£ |
| 50-100 | 0.30 | é€‚ä¸­ |
| > 100 | 0.25 | è¾ƒä¸¥æ ¼ï¼Œæé«˜èšç±»ç²¾åº¦ |

### min_samples å‚æ•°é€‰æ‹©

| æ•°æ®è§„æ¨¡ | æ¨è min_samples | è®¡ç®—å…¬å¼ |
|----------|------------------|----------|
| < 15 | 3 | å›ºå®šæœ€å°å€¼ |
| 15-50 | 3 | ä¿æŒè¾ƒä½é˜ˆå€¼ |
| 50-100 | 4 | é€‚åº¦æé«˜ |
| > 100 | max(5, N//50) | çº¿æ€§å¢é•¿ |

**è®¾è®¡ç†å¿µï¼š**

- å°æ•°æ®é›†: ä½¿ç”¨è¾ƒå°çš„ min_samplesï¼Œé¿å…å°†æ‰€æœ‰ç‚¹éƒ½è§†ä¸ºå™ªéŸ³
- å¤§æ•°æ®é›†: ä½¿ç”¨è¾ƒå¤§çš„ min_samplesï¼Œæé«˜èšç±»è´¨é‡

---

## è´¨é‡è¯„ä¼°æŒ‡æ ‡

### 1. Silhouette Score (è½®å»“ç³»æ•°)

```python
# èŒƒå›´: [-1, 1]ï¼Œè¶Šé«˜è¶Šå¥½
silhouette > 0.5:  ä¼˜ç§€ (ç°‡é—´åˆ†ç¦»åº¦é«˜)
silhouette > 0.3:  è‰¯å¥½ (ç°‡è¾ƒä¸ºæ˜ç¡®)
silhouette > 0.1:  ä¸€èˆ¬ (ç°‡è¾¹ç•Œæ¨¡ç³Š)
silhouette â‰¤ 0.1:  è¾ƒå·® (éœ€è¦è°ƒæ•´å‚æ•°)
```

### 2. Davies-Bouldin Index (DBI)

```python
# èŒƒå›´: [0, +âˆ)ï¼Œè¶Šå°è¶Šå¥½
dbi < 1:          ä¼˜ç§€ (ç°‡é—´åˆ†ç¦»åº¦å¥½)
dbi = 1-2:         è‰¯å¥½
dbi > 2:           éœ€è¦æ”¹è¿›
```

**è®¡ç®—å…¬å¼ï¼š**

```
DBI = (1/k) Ã— Î£(max[(Ïƒi + Ïƒj) / d(c_i, c_j)])

å…¶ä¸­:
k = èšç±»æ•°é‡
Ïƒi = ç°‡ i çš„å¹³å‡è·ç¦» (ç°‡å†…è·ç¦»)
d(c_i, c_j) = ç°‡ i å’Œç°‡ j ä¸­å¿ƒçš„è·ç¦» (ç°‡é—´è·ç¦»)
```

### èšç±»ç»“æœè§£è¯»

| æŒ‡æ ‡ç»„åˆ | å«ä¹‰ | å»ºè®® |
|----------|------|------|
| é«˜ Silhouette + ä½ DBI | ç†æƒ³èšç±» | ä¿æŒå½“å‰å‚æ•° |
| ä½ Silhouette + é«˜ DBI | èšç±»è´¨é‡å·® | è°ƒæ•´ eps æˆ– min_samples |
| å¤šä¸ªå°èšç±» + é«˜å™ªéŸ³ç‚¹ | eps å¤ªå° | å¢å¤§ eps |
| å°‘æ•°å¤§èšç±» + ä½å™ªéŸ³ç‚¹ | eps å¤ªå¤§ | å‡å° eps |
| æ‰€æœ‰ç‚¹éƒ½æ˜¯å™ªéŸ³ | min_samples å¤ªå¤§ | å‡å° min_samples |

---

## ä½¿ç”¨æŒ‡å—

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# åŸºæœ¬ç”¨æ³•
python lib/semantic_clustering.py \
  --input data.json \
  --output results.json

# ä»æ ‡å‡†è¾“å…¥è¯»å–
echo '{"texts": ["æ–‡æœ¬1", "æ–‡æœ¬2"]}' | \
  python lib/semantic_clustering.py --stdin

# è‡ªå®šä¹‰å‚æ•°
python lib/semantic_clustering.py \
  --input data.json \
  --output results.json \
  --eps 0.3 \
  --min-samples 4 \
  --min-length 5

# å¯ç”¨å‚æ•°è‡ªåŠ¨ä¼˜åŒ–
python lib/semantic_clustering.py \
  --input data.json \
  --auto-optimize
```

### Python API è°ƒç”¨

```python
from lib.semantic_clustering import process_texts

texts = [
    "è¿™ä¸ªäº§å“çœŸçš„å¾ˆéš¾ç”¨",
    "æ±‚æ¨èç±»ä¼¼çš„äº§å“",
    "æ€ä¹ˆä½¿ç”¨è¿™ä¸ªåŠŸèƒ½ï¼Ÿ",
    "ä¸é”™ï¼ŒæŒºå¥½ç”¨çš„",
    # ... æ›´å¤šæ–‡æœ¬
]

# è‡ªåŠ¨æ¨¡å¼ï¼ˆå‚æ•°è‡ªé€‚åº”ï¼‰
clusters = process_texts(texts)

# æ‰‹åŠ¨æŒ‡å®šå‚æ•°
clusters = process_texts(
    texts,
    eps=0.28,
    min_samples=4,
    min_length=4,
    auto_optimize=False
)

# å¯ç”¨å‚æ•°ä¼˜åŒ–
clusters = process_texts(
    texts,
    auto_optimize=True  # ç½‘æ ¼æœç´¢æœ€ä¼˜å‚æ•°
)

# è¾“å‡ºæ ¼å¼
for cluster in clusters:
    print(f"èšç±»å¤§å°: {cluster['size']}")
    print(f"ä»£è¡¨æ€§æ–‡æœ¬: {cluster['representative_text']}")
    print(f"åŒ…å«æ–‡æœ¬: {cluster['texts']}")
    print("---")
```

### è¾“å…¥æ ¼å¼

**ç›´æ¥æ•°ç»„ï¼š**

```json
[
  "æ–‡æœ¬1",
  "æ–‡æœ¬2",
  "æ–‡æœ¬3"
]
```

**å¯¹è±¡æ ¼å¼ï¼š**

```json
{
  "texts": [
    "æ–‡æœ¬1",
    "æ–‡æœ¬2",
    "æ–‡æœ¬3"
  ]
}
```

### è¾“å‡ºæ ¼å¼

```json
{
  "success": true,
  "clusters": [
    {
      "representative_text": "ä»£è¡¨æ€§æ–‡æœ¬",
      "size": 15,
      "texts": [
        "æ–‡æœ¬1",
        "æ–‡æœ¬2",
        ...
      ]
    }
  ],
  "total_clusters": 5,
  "total_texts": 75
}
```

---

## æ€§èƒ½è°ƒä¼˜

### æ•°æ®è§„æ¨¡å»ºè®®

| è§„æ¨¡ | å»ºè®®æ“ä½œ |
|------|----------|
| < 50 | ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œæˆ–å¯ç”¨ auto_optimize |
| 50-200 | æ‰‹åŠ¨è°ƒæ•´å‚æ•°ï¼Œæˆ–åˆ†æ‰¹å¤„ç† |
| 200-500 | åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ 100-200 æ¡ |
| > 500 | åˆ†æ‰¹å¤„ç† + è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„ Embedding æ¨¡å‹ |

### æ‰¹å¤„ç†ç­–ç•¥

```python
def batch_process(texts, batch_size=150):
    """å¤§æ‰¹é‡æ•°æ®åˆ†æ‰¹å¤„ç†"""
    all_clusters = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        clusters = process_texts(batch)
        all_clusters.extend(clusters)
        logger.info(f"å·²å¤„ç† {i+len(batch)}/{len(texts)} æ¡")

    return all_clusters
```

### API æˆæœ¬ä¼˜åŒ–

æ™ºè°±AI Embedding API è®¡è´¹ï¼š
- embedding-3: Â¥0.0005/åƒ tokens
- å¹³å‡æ¯æ¡çº¦ 20 tokens
- 1000 æ¡æ–‡æœ¬ â‰ˆ Â¥0.01

**ä¼˜åŒ–å»ºè®®ï¼š**

1. **é¢„å…ˆè¿‡æ»¤**: ä½¿ç”¨ DataCleaner è¿‡æ»¤å™ªéŸ³ï¼Œå‡å°‘ API è°ƒç”¨
2. **å»é‡**: ç›¸åŒæ–‡æœ¬åª embedding ä¸€æ¬¡
3. **ç¼“å­˜**: å¯¹é‡å¤æŸ¥è¯¢è¿›è¡Œç¼“å­˜

### å¸¸è§æ€§èƒ½é—®é¢˜

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| å¤„ç†æ—¶é—´è¿‡é•¿ | API è°ƒç”¨å¤ªé¢‘ç¹ | æ‰¹é‡å¤„ç† + é¢„è¿‡æ»¤ |
| èšç±»æ•°é‡è¿‡å¤š | eps å¤ªå° | å¢å¤§ eps |
| å¤§é‡å™ªéŸ³ç‚¹ | min_samples å¤ªå¤§ | å‡å° min_samples |
| Silhouette Score å¾ˆä½ | æ•°æ®è´¨é‡å·® | åŠ å¼ºæ•°æ®æ¸…æ´— |

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é”™è¯¯

#### 1. æœªæ‰¾åˆ° GLM_API_KEY

```
é”™è¯¯: ValueError: æœªæ‰¾åˆ° GLM_API_KEY
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $GLM_API_KEY

# æˆ–åˆ›å»º .env.local æ–‡ä»¶
echo "GLM_API_KEY=your_key_here" > .env.local
```

#### 2. API è¯·æ±‚å¤±è´¥

```
é”™è¯¯: API é”™è¯¯: 401 - {"error":{"message":"æ— æ•ˆçš„ API é”™è¯¯","type":"invalid_api_error"}}
```

**è§£å†³æ–¹æ¡ˆï¼š**

- æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
- ç¡®è®¤è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢
- æ£€æŸ¥ç½‘ç»œè¿æ¥

#### 3. èšç±»ç»“æœä¸ºç©º

```
è­¦å‘Š: èšç±»æ•°é‡è¿‡å°‘ï¼Œæ— æ³•è®¡ç®—è´¨é‡æŒ‡æ ‡
```

**å¯èƒ½åŸå› ï¼š**

1. **æ•°æ®é‡å¤ªå°‘**: æ¸…æ´—åå‰©ä½™æ–‡æœ¬ä¸è¶³ 10 æ¡
   - è§£å†³: å¢åŠ è¾“å…¥æ•°æ®é‡

2. **å‚æ•°è¿‡äºä¸¥æ ¼**: eps å¤ªå°æˆ– min_samples å¤ªå¤§
   - è§£å†³: æ”¾å®½å‚æ•°

3. **æ•°æ®è´¨é‡å·®**: å¤§é‡å™ªéŸ³æ–‡æœ¬æœªè¢«è¿‡æ»¤
   - è§£å†³: è°ƒæ•´ DataCleaner é…ç½®

#### 4. æ‰€æœ‰ç‚¹éƒ½æ˜¯å™ªéŸ³

```
èšç±»å®Œæˆ: 0 ä¸ªèšç±», 150 ä¸ªå™ªéŸ³ç‚¹
```

**åŸå› :** min_samples è®¾ç½®å¤ªå¤§

**è§£å†³æ–¹æ¡ˆ:**

```python
# å‡å° min_samples
clusters = process_texts(texts, min_samples=3)
```

---

## é«˜çº§é…ç½®

### è‡ªå®šä¹‰å™ªéŸ³è§„åˆ™

```python
# æ‰©å±• DataCleaner çš„å™ªéŸ³æ¨¡å¼
cleaner = DataCleaner()
cleaner.NOISE_PATTERNS.append(r'^è‡ªå®šä¹‰æ­£åˆ™$')
cleaner.NOISE_PHRASES.extend(['è‡ªå®šä¹‰çŸ­è¯­'])
```

### è‡ªå®šä¹‰ç™½åå•

```python
# æ·»åŠ ç‰¹å®šé¢†åŸŸçš„ç™½åå•å…³é”®è¯
cleaner.WHITELIST_KEYWORDS.extend([
    'é¢†åŸŸç‰¹å®šè¯1',
    'é¢†åŸŸç‰¹å®šè¯2'
])
```

### è°ƒæ•´è´¨é‡è¯„åˆ†æƒé‡

```python
def custom_score(text):
    score = 1.0

    # è‡ªå®šä¹‰è§„åˆ™
    if 'å…³é”®è¯' in text:
        score += 3.0  # æ›´é«˜çš„æƒé‡

    # ... æ›´å¤šè‡ªå®šä¹‰é€»è¾‘

    return score
```

---

## ç®—æ³•å¯¹æ¯”

### DBSCAN vs K-Means vs å±‚æ¬¡èšç±»

| ç‰¹æ€§ | DBSCAN | K-Means | å±‚æ¬¡èšç±» |
|------|--------|---------|----------|
| èšç±»æ•°é‡ | è‡ªåŠ¨å‘ç° | éœ€é¢„å…ˆæŒ‡å®š | éœ€æŒ‡å®šé˜ˆå€¼ |
| å™ªéŸ³å¤„ç† | è‡ªåŠ¨è¯†åˆ«å™ªéŸ³ | å¼ºåˆ¶åˆ†é… | è¾ƒå¼± |
| å½¢çŠ¶æ”¯æŒ | ä»»æ„å½¢çŠ¶ | çƒå½¢ | ä»»æ„å½¢çŠ¶ |
| å‚æ•°æ•æ„Ÿæ€§ | ä¸­ç­‰ | è¾ƒé«˜ | è¾ƒé«˜ |
| è®¡ç®—å¤æ‚åº¦ | O(nÂ²) | O(nkt) | O(nÂ³) |
| å¤§æ•°æ®é€‚ç”¨ | è¾ƒå·® | è‰¯å¥½ | å·® |

### ä¸ºä»€ä¹ˆé€‰æ‹© DBSCANï¼Ÿ

1. **æ— éœ€æŒ‡å®šèšç±»æ•°é‡**: ç”¨æˆ·ç—›ç‚¹æ•°é‡æœªçŸ¥
2. **å™ªéŸ³å¤„ç†èƒ½åŠ›å¼º**: ç¤¾äº¤åª’ä½“è¯„è®ºæœ‰å¤§é‡å™ªéŸ³
3. **å‘ç°ä»»æ„å½¢çŠ¶**: ç—›ç‚¹èšç±»å½¢çŠ¶ä¸è§„åˆ™
4. **è¯­ä¹‰é€‚é…**: ç»“åˆä½™å¼¦è·ç¦»æ•ˆæœæ›´ä½³

---

## é™„å½•

### A. ç¯å¢ƒè¦æ±‚

```bash
# Python ç‰ˆæœ¬
>= 3.8

# ä¾èµ–åŒ…
numpy>=1.20.0
scikit-learn>=0.24.0
python-dotenv>=0.19.0
```

### B. ä¾èµ–å®‰è£…

```bash
pip install numpy scikit-learn python-dotenv
```

### C. API è·å–

1. è®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
2. æ³¨å†Œè´¦å·å¹¶å®Œæˆè®¤è¯
3. åˆ›å»º API Key
4. é…ç½®åˆ°ç¯å¢ƒå˜é‡

### D. ç›¸å…³æ–‡æ¡£

- [æ™ºè°±AI Embedding API æ–‡æ¡£](https://open.bigmodel.cn/dev/api#embedding)
- [scikit-learn DBSCAN æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)
- [ä½™å¼¦ç›¸ä¼¼åº¦åŸç†](https://en.wikipedia.org/wiki/Cosine_similarity)

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*
*æœ€åæ›´æ–°: 2025å¹´*
*ç»´æŠ¤è€…: SeekMoney AI å›¢é˜Ÿ*
